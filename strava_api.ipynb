{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import requests\n",
    "import urllib3\n",
    "import secrets\n",
    "import pandas as pd\n",
    "import polyline\n",
    "import folium\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "from meteostat import Stations, Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable insecure request warnings from urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strava API Request\n",
    "    - https://developers.strava.com/docs/reference/\n",
    "    - within this repo there is a .gitignore file which ignores secrets.py this is where the strava_payload is to handle Strava API request\n",
    "        - values in secrets.py for Strava API request:\n",
    "            - client_id\n",
    "            - client_secret\n",
    "            - refresh_token\n",
    "            - grant_type\n",
    "            - f \n",
    "                - which is a request for json files to the API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting Strava token... \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all activities is NOT populated\n",
      "all activities is populated\n",
      "all activities is populated\n",
      "all activities is populated\n",
      "breaking out of Strava while loop because the response is zero, indicating no more activities.\n",
      "Total Activities:  56\n"
     ]
    }
   ],
   "source": [
    "auth_url = 'https://www.strava.com/oauth/token'\n",
    "activities_url = 'https://www.strava.com/api/v3/athlete/activities'\n",
    "\n",
    "# Request Strava Token\n",
    "print('Requesting Strava token... \\n')\n",
    "res = requests.post(auth_url, data=secrets.strava_payload, verify=False)\n",
    "strava_access_token = res.json()['access_token']\n",
    "\n",
    "# Set the authorization header using the obtained access token\n",
    "header = {'Authorization': 'Bearer ' + strava_access_token}\n",
    "\n",
    "strava_requests_page_num = 1\n",
    "all_activities = []\n",
    "\n",
    "while True:\n",
    "    # Prepare the parameters for paginated request\n",
    "    strava_param = {'per_page' : 15, 'page' : strava_requests_page_num}\n",
    "    # Send GET request to retrieve Strava activity data\n",
    "    strava_dataset = requests.get(activities_url, headers=header, params=strava_param).json()\n",
    "\n",
    "    if len(strava_dataset) == 0:\n",
    "        print('breaking out of Strava while loop because the response is zero, indicating no more activities.')\n",
    "        break\n",
    "\n",
    "    if all_activities:\n",
    "        print('all activities is populated')\n",
    "        all_activities.extend(strava_dataset)\n",
    "\n",
    "    else:\n",
    "        print('all activities is NOT populated')\n",
    "        all_activities = strava_dataset\n",
    "\n",
    "    strava_requests_page_num += 1\n",
    "\n",
    "print('Total Activities: ', len(all_activities))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating pandas dataframe for all activites from Strava api\n",
    "    - Contains all activites\n",
    "        - Running\n",
    "        - Walking\n",
    "        - Hiking\n",
    "        - Biking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strava_activites = pd.DataFrame(data=all_activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting and Cleaning Activities Data\n",
    "    - Where can data be cleaned?\n",
    "    - Many Columns are not filled with information because there is no use of a watch or heart monitor.\n",
    "    - Not intersted in the social information of Strava\n",
    "        - ie, photos, kudos\n",
    "    - location_city, location_state actually contain no information\n",
    "        - We can get location information from Google Polyline information found in the 'map' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_state</th>\n",
       "      <th>athlete</th>\n",
       "      <th>name</th>\n",
       "      <th>distance</th>\n",
       "      <th>moving_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>total_elevation_gain</th>\n",
       "      <th>type</th>\n",
       "      <th>sport_type</th>\n",
       "      <th>workout_type</th>\n",
       "      <th>...</th>\n",
       "      <th>upload_id_str</th>\n",
       "      <th>external_id</th>\n",
       "      <th>from_accepted_tag</th>\n",
       "      <th>pr_count</th>\n",
       "      <th>total_photo_count</th>\n",
       "      <th>has_kudoed</th>\n",
       "      <th>suffer_score</th>\n",
       "      <th>average_watts</th>\n",
       "      <th>kilojoules</th>\n",
       "      <th>device_watts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>{'id': 8586088, 'resource_state': 1}</td>\n",
       "      <td>PMRP : Sore Heel Loop</td>\n",
       "      <td>8343.9</td>\n",
       "      <td>2228</td>\n",
       "      <td>2278</td>\n",
       "      <td>258.1</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10190674906</td>\n",
       "      <td>C8640F5F-E651-4E80-8473-01FD967B0A27-activity.fit</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{'id': 8586088, 'resource_state': 1}</td>\n",
       "      <td>RRG : Cherokee Arch</td>\n",
       "      <td>6706.5</td>\n",
       "      <td>5137</td>\n",
       "      <td>6285</td>\n",
       "      <td>429.2</td>\n",
       "      <td>Hike</td>\n",
       "      <td>Hike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10189590699</td>\n",
       "      <td>154882AE-0CE2-4C22-B39C-43C514477C1E-activity.fit</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'id': 8586088, 'resource_state': 1}</td>\n",
       "      <td>PMRP : Sore Heel Loop and Drive By Loop</td>\n",
       "      <td>8693.2</td>\n",
       "      <td>2864</td>\n",
       "      <td>3001</td>\n",
       "      <td>317.7</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10170403908</td>\n",
       "      <td>71247EE3-700D-4881-87D0-B8B996F29BBD-activity.fit</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>{'id': 8586088, 'resource_state': 1}</td>\n",
       "      <td>RRG : Rush Trail to Grayâ€™s Arch Loop</td>\n",
       "      <td>6312.2</td>\n",
       "      <td>2374</td>\n",
       "      <td>2448</td>\n",
       "      <td>173.8</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10150965476</td>\n",
       "      <td>3A315073-851C-4478-8D23-F4D440BAA704-activity.fit</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>{'id': 8586088, 'resource_state': 1}</td>\n",
       "      <td>PMRP : Lode Loop and Drive By Loop</td>\n",
       "      <td>5532.4</td>\n",
       "      <td>1884</td>\n",
       "      <td>1967</td>\n",
       "      <td>124.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10143932040</td>\n",
       "      <td>7D43355C-FECB-473B-8263-E7C4BDB870DE-activity.fit</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   resource_state                               athlete  \\\n",
       "0               2  {'id': 8586088, 'resource_state': 1}   \n",
       "1               2  {'id': 8586088, 'resource_state': 1}   \n",
       "2               2  {'id': 8586088, 'resource_state': 1}   \n",
       "3               2  {'id': 8586088, 'resource_state': 1}   \n",
       "4               2  {'id': 8586088, 'resource_state': 1}   \n",
       "\n",
       "                                      name  distance  moving_time  \\\n",
       "0                    PMRP : Sore Heel Loop    8343.9         2228   \n",
       "1                      RRG : Cherokee Arch    6706.5         5137   \n",
       "2  PMRP : Sore Heel Loop and Drive By Loop    8693.2         2864   \n",
       "3     RRG : Rush Trail to Grayâ€™s Arch Loop    6312.2         2374   \n",
       "4       PMRP : Lode Loop and Drive By Loop    5532.4         1884   \n",
       "\n",
       "   elapsed_time  total_elevation_gain  type sport_type  workout_type  ...  \\\n",
       "0          2278                 258.1   Run        Run           0.0  ...   \n",
       "1          6285                 429.2  Hike       Hike           NaN  ...   \n",
       "2          3001                 317.7   Run        Run           0.0  ...   \n",
       "3          2448                 173.8   Run        Run           0.0  ...   \n",
       "4          1967                 124.0   Run        Run           0.0  ...   \n",
       "\n",
       "   upload_id_str                                        external_id  \\\n",
       "0    10190674906  C8640F5F-E651-4E80-8473-01FD967B0A27-activity.fit   \n",
       "1    10189590699  154882AE-0CE2-4C22-B39C-43C514477C1E-activity.fit   \n",
       "2    10170403908  71247EE3-700D-4881-87D0-B8B996F29BBD-activity.fit   \n",
       "3    10150965476  3A315073-851C-4478-8D23-F4D440BAA704-activity.fit   \n",
       "4    10143932040  7D43355C-FECB-473B-8263-E7C4BDB870DE-activity.fit   \n",
       "\n",
       "  from_accepted_tag pr_count  total_photo_count has_kudoed suffer_score  \\\n",
       "0             False        6                  0      False          NaN   \n",
       "1             False        0                  0      False          NaN   \n",
       "2             False        0                  0      False          NaN   \n",
       "3             False        0                  0      False          NaN   \n",
       "4             False        0                  0      False          NaN   \n",
       "\n",
       "  average_watts  kilojoules  device_watts  \n",
       "0           NaN         NaN           NaN  \n",
       "1           NaN         NaN           NaN  \n",
       "2           NaN         NaN           NaN  \n",
       "3           NaN         NaN           NaN  \n",
       "4           NaN         NaN           NaN  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_strava_activites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resource_state',\n",
       " 'athlete',\n",
       " 'name',\n",
       " 'distance',\n",
       " 'moving_time',\n",
       " 'elapsed_time',\n",
       " 'total_elevation_gain',\n",
       " 'type',\n",
       " 'sport_type',\n",
       " 'workout_type',\n",
       " 'id',\n",
       " 'start_date',\n",
       " 'start_date_local',\n",
       " 'timezone',\n",
       " 'utc_offset',\n",
       " 'location_city',\n",
       " 'location_state',\n",
       " 'location_country',\n",
       " 'achievement_count',\n",
       " 'kudos_count',\n",
       " 'comment_count',\n",
       " 'athlete_count',\n",
       " 'photo_count',\n",
       " 'map',\n",
       " 'trainer',\n",
       " 'commute',\n",
       " 'manual',\n",
       " 'private',\n",
       " 'visibility',\n",
       " 'flagged',\n",
       " 'gear_id',\n",
       " 'start_latlng',\n",
       " 'end_latlng',\n",
       " 'average_speed',\n",
       " 'max_speed',\n",
       " 'has_heartrate',\n",
       " 'heartrate_opt_out',\n",
       " 'display_hide_heartrate_option',\n",
       " 'elev_high',\n",
       " 'elev_low',\n",
       " 'upload_id',\n",
       " 'upload_id_str',\n",
       " 'external_id',\n",
       " 'from_accepted_tag',\n",
       " 'pr_count',\n",
       " 'total_photo_count',\n",
       " 'has_kudoed',\n",
       " 'suffer_score',\n",
       " 'average_watts',\n",
       " 'kilojoules',\n",
       " 'device_watts']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_strava_activites_columns = all_strava_activites.columns.to_list()\n",
    "all_strava_activites_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to drop from the DataFrame\n",
    "columns_to_drop = ['athlete',\n",
    "                   'resource_state', \n",
    "                   'sport_type', \n",
    "                   'workout_type',\n",
    "                   'location_city',\n",
    "                   'location_state',\n",
    "                   'location_country', \n",
    "                   'kudos_count', \n",
    "                   'comment_count', \n",
    "                   'athlete_count', \n",
    "                   'photo_count', \n",
    "                   'trainer', \n",
    "                   'commute', \n",
    "                   'manual', \n",
    "                   'private',\n",
    "                   'visibility', \n",
    "                   'flagged', \n",
    "                   'gear_id', \n",
    "                   'has_heartrate', \n",
    "                   'heartrate_opt_out', \n",
    "                   'display_hide_heartrate_option', \n",
    "                   'from_accepted_tag', \n",
    "                   'total_photo_count', \n",
    "                   'has_kudoed', \n",
    "                   'average_watts', \n",
    "                   'kilojoules',\n",
    "                   'achievement_count',\n",
    "                   'device_watts',\n",
    "                   'upload_id_str',\n",
    "                   'upload_id',\n",
    "                   'external_id', \n",
    "                   'suffer_score']\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "all_strava_activites.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "columns = all_strava_activites.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'distance',\n",
       " 'moving_time',\n",
       " 'elapsed_time',\n",
       " 'total_elevation_gain',\n",
       " 'type',\n",
       " 'id',\n",
       " 'start_date',\n",
       " 'start_date_local',\n",
       " 'timezone',\n",
       " 'utc_offset',\n",
       " 'map',\n",
       " 'start_latlng',\n",
       " 'end_latlng',\n",
       " 'average_speed',\n",
       " 'max_speed',\n",
       " 'elev_high',\n",
       " 'elev_low',\n",
       " 'pr_count']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Pandas Dataframe for just the activity of Running\n",
    "    - Filter data with the 'type' is equal to 'Run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_data = all_strava_activites.loc[all_strava_activites['type'] == 'Run']\n",
    "\n",
    "# Reset the index of the DataFrame after filtering\n",
    "run_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversions for Metrics\n",
    "    - Calculate miles, minutes, and hours\n",
    "    - 'distance' is in meters\n",
    "    - 'moving_time' is in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Calculate and add new columns, 'distance_miles', 'moving_time_minutes', and 'moving_time_hours, rounded to 2 decimal places\n",
    "run_data['distance_miles'] = round(run_data.loc[:,('distance')] * 0.00062137119, 2)\n",
    "run_data['moving_time_minutes'] = round(run_data.loc[:,('moving_time')] / 60, 2)\n",
    "run_data['moving_time_hours'] = round(run_data.loc[:,('moving_time')] / 3600, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Distance (miles): 4.05\n",
      "Average Time Ran (minutes): 40.65\n",
      "Longest Run: 9.62 miles\n",
      "Longest Duration: 117.57 minutes. Converted to hours: 1.96\n",
      "Total Distance Covered to the date (miles): 157.77\n"
     ]
    }
   ],
   "source": [
    "# Calculate averages for miles and time\n",
    "average_distance_miles = round(run_data['distance_miles'].mean(), 2)\n",
    "print(\"Average Distance (miles):\", average_distance_miles)\n",
    "average_time_minutes = round(run_data['moving_time_minutes'].mean(), 2)\n",
    "print(\"Average Time Ran (minutes):\", average_time_minutes)\n",
    "\n",
    "# Calculate distance for longest run\n",
    "max_distance_ran = round(run_data['distance_miles'].max(), 2)\n",
    "print(\"Longest Run:\", max_distance_ran, \"miles\")\n",
    "\n",
    "# Calculate total time ran\n",
    "max_duration_mintues = round(run_data['moving_time_minutes'].max(), 2)\n",
    "max_duration_hours = round(run_data['moving_time_hours'].max(), 2)\n",
    "print(\"Longest Duration:\", max_duration_mintues,\"minutes. Converted to hours:\", max_duration_hours)\n",
    "\n",
    "# Calculate total miles ran\n",
    "total_distance_miles = round(run_data['distance'].sum() * 0.00062137119, 2)\n",
    "print(\"Total Distance Covered to the date (miles):\", total_distance_miles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve and Decode Polyline for mapping\n",
    "    - Google Polyline information:\n",
    "        - https://developers.google.com/maps/documentation/utilities/polylineutility\n",
    "    - When Polyline is decoded it outputs longitude and latitude listings for activity.\n",
    "    - Use of polyline module\n",
    "        - https://pypi.org/project/polyline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame 'all_run_map_data' form the 'map' column in 'run_data' for polyline data\n",
    "all_run_map_data = pd.DataFrame(run_data['map'].to_list())\n",
    "\n",
    "# Remove the first character 'a' from the 'id' column to match id's between two DataFrames\n",
    "all_run_map_data['id'] = all_run_map_data['id'].str.slice(start=1)\n",
    "\n",
    "# Drop the 'map' column from 'run_data'\n",
    "run_data.drop(columns='map', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame 'decoded_df_all' with columns 'id' and 'decoded_polyline'\n",
    "decoded_df_all = pd.DataFrame(columns=['id', 'decoded_polyline'])\n",
    "\n",
    "# Iterate over each row in 'all_run_map_data'\n",
    "for index, row in all_run_map_data.iterrows():\n",
    "    polyline_str = row['summary_polyline']\n",
    "\n",
    "    # Decode the polyline string using 'polyline.decode()'\n",
    "    decoded_polyline = polyline.decode(polyline_str)\n",
    "\n",
    "    # Append the decoded polyline and its corresponding ID to 'decoded_df_all'\n",
    "    decoded_df_all = decoded_df_all.append({'id' : row['id'], 'decoded_polyline' : decoded_polyline}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID column datatype in Run Data:  int64\n",
      "ID column datatype in Decoded Data:  object\n",
      "ID column datatype of Decoded Data after convert:  int64\n"
     ]
    }
   ],
   "source": [
    "# Print the data type of the 'id' column in both DataFrames\n",
    "print('ID column datatype in Run Data: ', run_data['id'].dtype)\n",
    "print('ID column datatype in Decoded Data: ', decoded_df_all['id'].dtype)\n",
    "\n",
    "# Convert the 'id' column in 'decoded_df_all' to integer data type\n",
    "decoded_df_all['id'] = decoded_df_all['id'].astype(int)\n",
    "print('ID column datatype of Decoded Data after convert: ', decoded_df_all['id'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'run_data' with 'decoded_df_all' on the 'id' column\n",
    "run_data = pd.merge(run_data, decoded_df_all, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Run Data\n",
    "    - Merge run data with weather data\n",
    "    - merge on 'start_date'\n",
    "        - change format of date to match between the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime64[ns, UTC]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'start_date' to datetime format to be index for later merge with weather data\n",
    "run_data['start_date'] = pd.to_datetime(run_data['start_date'])\n",
    "run_data['start_date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'start_date' column to date only (removing time information)\n",
    "run_data['start_date'] = run_data['start_date'].dt.date\n",
    "print(run_data['start_date'].dtype)\n",
    "\n",
    "# Convert 'start_date' column to datetime format\n",
    "run_data['start_date'] = pd.to_datetime(run_data['start_date'])\n",
    "print(run_data['start_date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data\n",
    "    - Using Meteostat\n",
    "        - https://dev.meteostat.net/\n",
    "    - Using run_data to acquire coordinate input to find closest Weather Station to get weather data\n",
    "    - Using run_data to acquire timescale for weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first entry of row to access lat and lon values\n",
    "coords = run_data['start_latlng'].loc[0]\n",
    "\n",
    "# Extracting the latitude and lon from the coords tuple\n",
    "lat = coords[0]\n",
    "lon = coords[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use last entry in run data as start date for weather model\n",
    "start = pd.to_datetime(run_data['start_date'].iloc[-1])\n",
    "# Use datetime.now() to get current date to ensure data is up to date\n",
    "end = datetime.now()\n",
    "model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>wmo</th>\n",
       "      <th>icao</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>timezone</th>\n",
       "      <th>hourly_start</th>\n",
       "      <th>hourly_end</th>\n",
       "      <th>daily_start</th>\n",
       "      <th>daily_end</th>\n",
       "      <th>monthly_start</th>\n",
       "      <th>monthly_end</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CZF98</th>\n",
       "      <td>Jackson Carroll Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>KY</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>KJKL</td>\n",
       "      <td>37.5914</td>\n",
       "      <td>-83.3144</td>\n",
       "      <td>421.0</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>2023-07-23</td>\n",
       "      <td>2022-04-24</td>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>35724.868492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name country region   wmo  icao  latitude  \\\n",
       "id                                                                    \n",
       "CZF98  Jackson Carroll Airport      US     KY  <NA>  KJKL   37.5914   \n",
       "\n",
       "       longitude  elevation          timezone hourly_start hourly_end  \\\n",
       "id                                                                      \n",
       "CZF98   -83.3144      421.0  America/New_York   2022-04-23 2023-07-23   \n",
       "\n",
       "      daily_start  daily_end monthly_start monthly_end      distance  \n",
       "id                                                                    \n",
       "CZF98  2022-04-24 2022-04-26           NaT         NaT  35724.868492  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use meteostat Stations() instance to acquire information for nearest weather station to run location\n",
    "stations = Stations()\n",
    "stations = stations.nearby(lat=lat, lon=lon)\n",
    "weather_station = stations.fetch(1)\n",
    "\n",
    "weather_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use meteostat Daily() instance to acquire weather data based on the start date of the oldest run and ending to current date\n",
    "data = Daily(weather_station.iloc[:], start, end, model)\n",
    "data = data.normalize()\n",
    "data = data.fetch()\n",
    "\n",
    "# Create DataFrame for weather_data\n",
    "weather_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-19</th>\n",
       "      <td>72.14</td>\n",
       "      <td>66.92</td>\n",
       "      <td>26.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1018.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-20</th>\n",
       "      <td>74.30</td>\n",
       "      <td>69.08</td>\n",
       "      <td>27.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1016.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-21</th>\n",
       "      <td>75.02</td>\n",
       "      <td>69.98</td>\n",
       "      <td>28.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.91</td>\n",
       "      <td>1013.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-22</th>\n",
       "      <td>74.30</td>\n",
       "      <td>64.94</td>\n",
       "      <td>28.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>356.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1012.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-23</th>\n",
       "      <td>74.66</td>\n",
       "      <td>62.78</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>1013.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tavg   tmin  tmax  prcp  snow   wdir  wspd    pres\n",
       "time                                                           \n",
       "2022-01-15    NaN    NaN   NaN   NaN   NaN    NaN   NaN     NaN\n",
       "2022-01-16    NaN    NaN   NaN   NaN   NaN    NaN   NaN     NaN\n",
       "2022-01-17    NaN    NaN   NaN   NaN   NaN    NaN   NaN     NaN\n",
       "2022-01-18    NaN    NaN   NaN   NaN   NaN    NaN   NaN     NaN\n",
       "2022-01-19    NaN    NaN   NaN   NaN   NaN    NaN   NaN     NaN\n",
       "...           ...    ...   ...   ...   ...    ...   ...     ...\n",
       "2023-07-19  72.14  66.92  26.7   5.8   NaN  344.0  1.43  1018.8\n",
       "2023-07-20  74.30  69.08  27.2   6.4   NaN  224.0  3.73  1016.1\n",
       "2023-07-21  75.02  69.98  28.3   2.5   NaN  320.0  3.91  1013.4\n",
       "2023-07-22  74.30  64.94  28.5   1.2   NaN  356.0  2.73  1012.3\n",
       "2023-07-23  74.66  62.78  30.0   0.0   NaN  317.0  4.04  1013.6\n",
       "\n",
       "[555 rows x 8 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'tavg' and 'tmin' from Celsius to Fahrenheit and round to 2 decimal places.\n",
    "weather_data['tavg'] = weather_data.apply(lambda x : round((9/5)*x['tavg']+32,2), axis=1)\n",
    "weather_data['tmin'] = weather_data.apply(lambda x : round((9/5)*x['tmin']+32,2), axis=1)\n",
    "# Convert the 'wspd' column from km/h to mph and round to 2 decimal places.\n",
    "weather_data['wspd'] = weather_data.apply(lambda x : round(x['wspd'] * 0.621371, 2), axis=1)\n",
    "# Drop 'wpgt' and 'tsun' because columns contian no data\n",
    "weather_data = weather_data.drop(['wpgt', 'tsun'], axis=1)\n",
    "\n",
    "weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'run_data' and 'weather_data' based on the 'start_date' column in 'run_data', index 'weather_data' using an inner join\n",
    "run_data = run_data.merge(weather_data, left_on='start_date', right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value for 'tavg', 'tmin', 'tmax', 'wspd', and 'pres'\n",
    "temp_mean = run_data['tavg'].mean()\n",
    "tmin_mean = run_data['tmin'].mean()\n",
    "tmax_mean = run_data['tmax'].mean()\n",
    "wspd_mean = run_data['wspd'].mean()\n",
    "pres_mean = run_data['pres'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mean to fill NaN values\n",
    "run_data['tavg'].fillna(int(temp_mean), inplace=True)\n",
    "run_data['tmin'].fillna(int(tmin_mean), inplace=True)\n",
    "run_data['tmax'].fillna(int(tmax_mean), inplace=True)\n",
    "run_data['wspd'].fillna(int(wspd_mean), inplace=True)\n",
    "run_data['pres'].fillna(int(pres_mean), inplace=True)\n",
    "\n",
    "# Fill NaN with 0.0 value\n",
    "run_data['prcp'].fillna(0.0, inplace=True)\n",
    "run_data['snow'].fillna(0.0, inplace=True)\n",
    "run_data['wdir'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going further into the data to only collect runs from RRGCC land\n",
    "    - For this particular project I want to focus on RRGCC owned and operated land\n",
    "    - Highlight the running opportunites on climber owned land\n",
    "        - Showcase different loops and routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the run data for RRGCC land and different running loops\n",
    "pmrp_run_data = run_data[run_data['name'].str.contains('PMRP', case=False, na=False)]\n",
    "rrg_run_data = run_data[run_data['name'].str.contains('RRG', case=False, na=False)]\n",
    "sore_heel_data = run_data[run_data['name'].str.contains('Sore Heel', case=False, na=False)]\n",
    "lode_loop_data = run_data[run_data['name'].str.contains('Lode Loop', case=False, na=False)]\n",
    "drive_by_loop_data = run_data[run_data['name'].str.contains('Drive By Loop', case=False,na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the run data for strict instances of running loops \n",
    "only_lode_loop = run_data[run_data['name'].str.contains(r'^PMRP : Lode Loop$', case=False)]\n",
    "only_sore_heel_loop = run_data[run_data['name'].str.contains(r'^PMRP : Sore Heel Loop$', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set csv path and save csv files\n",
    "all_csv_path = 'csv/run/run_data.csv'\n",
    "pmrp_csv_path = 'csv/run/pmrp_run_data.csv'\n",
    "rrg_csv_path = 'csv/run/rrg_run_data.csv'\n",
    "sore_heel_csv_path = 'csv/run/sore_heel_data.csv'\n",
    "only_sore_heel_loop_csv_path = 'csv/run/only_sore_heel_loop.csv'\n",
    "lode_loop_csv_path = 'csv/run/lode_loop_data.csv'\n",
    "only_lode_loop_csv_path = 'csv/run/only_lode_loop.csv'\n",
    "drive_by_csv_path = 'csv/run/drive_by_data.csv'\n",
    "\n",
    "weather_data_csv_path = 'csv/weather/only_weather_data.csv'\n",
    "\n",
    "run_data.to_csv(all_csv_path, index=False)\n",
    "pmrp_run_data.to_csv(pmrp_csv_path, index=False)\n",
    "rrg_run_data.to_csv(rrg_csv_path, index=False)\n",
    "sore_heel_data.to_csv(sore_heel_csv_path, index=False)\n",
    "only_sore_heel_loop.to_csv(only_sore_heel_loop_csv_path, index=False)\n",
    "lode_loop_data.to_csv(lode_loop_csv_path, index=False)\n",
    "only_lode_loop.to_csv(only_lode_loop_csv_path, index=False)\n",
    "drive_by_loop_data.to_csv(drive_by_csv_path, index=False)\n",
    "\n",
    "weather_data.to_csv(weather_data_csv_path, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
